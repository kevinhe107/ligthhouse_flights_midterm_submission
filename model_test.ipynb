{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "In this file, instructions how to approach the challenge can be found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to work on different types of Machine Learning problems:\n",
    "\n",
    "- **Regression Problem**: The goal is to predict delay of flights.\n",
    "- **(Stretch) Multiclass Classification**: If the plane was delayed, we will predict what type of delay it is (will be).\n",
    "- **(Stretch) Binary Classification**: The goal is to predict if the flight will be cancelled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Task: Regression Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is **ARR_DELAY**. We need to be careful which columns to use and which don't. For example, DEP_DELAY is going to be the perfect predictor, but we can't use it because in real-life scenario, we want to predict the delay before the flight takes of --> We can use average delay from earlier days but not the one from the actual flight we predict.  \n",
    "\n",
    "For example, variables **CARRIER_DELAY, WEATHER_DELAY, NAS_DELAY, SECURITY_DELAY, LATE_AIRCRAFT_DELAY** shouldn't be used directly as predictors as well. However, we can create various transformations from earlier values.\n",
    "\n",
    "We will be evaluating your models by predicting the ARR_DELAY for all flights **1 week in advance**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering will play a crucial role in this problems. We have only very little attributes so we need to create some features that will have some predictive power.\n",
    "\n",
    "- weather: we can use some weather API to look for the weather in time of the scheduled departure and scheduled arrival.\n",
    "- statistics (avg, mean, median, std, min, max...): we can take a look at previous delays and compute descriptive statistics\n",
    "- airports encoding: we need to think about what to do with the airports and other categorical variables\n",
    "- time of the day: the delay probably depends on the airport traffic which varies during the day.\n",
    "- airport traffic\n",
    "- unsupervised learning as feature engineering?\n",
    "- **what are the additional options?**: Think about what we could do more to improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = pd.read_csv('flights_big.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_test = pd.read_csv('flights_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* dropping massive null columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flights.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fl_date', 'mkt_unique_carrier', 'branded_code_share', 'mkt_carrier',\n",
       "       'mkt_carrier_fl_num', 'op_unique_carrier', 'tail_num',\n",
       "       'op_carrier_fl_num', 'origin_airport_id', 'origin', 'origin_city_name',\n",
       "       'dest_airport_id', 'dest', 'dest_city_name', 'crs_dep_time',\n",
       "       'crs_arr_time', 'dup', 'crs_elapsed_time', 'flights', 'distance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* dropping columns that mean the same thing and certain columns that don't mean anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_test1= flights_test.drop(['mkt_carrier', 'op_unique_carrier', 'flights', \n",
    "                          'tail_num', 'branded_code_share', 'op_carrier_fl_num'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* adding month, day of the week, day of the month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_test1['fl_date'] = pd.to_datetime(flights_test1['fl_date'], errors='coerce')\n",
    "flights_test1['month'] = flights_test1['fl_date'].dt.month\n",
    "flights_test1['day_of_week'] = flights_test1['fl_date'].dt.dayofweek\n",
    "flights_test1['day_of_month'] = flights_test1['fl_date'].dt.day\n",
    "flights_test1['year'] = flights_test1['fl_date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* splitting origin_city_name and dest_city_name from its short version name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_test1[['origin_city_name_only', 'origin_city_name_short']] = flights_test1['origin_city_name'].str.split(',', expand = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_test1[['dest_city_name_only', 'dest_city_name_short']] = flights_test1['dest_city_name'].str.split(',', expand = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping short hand version of city names\n",
    "flights_test1 = flights_test1.drop(['origin_city_name_short', 'dest_city_name_short', 'origin_city_name', 'dest_city_name', 'dest', 'origin'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_test1['origin_city_name_only'] = flights_test1['origin_city_name_only'].str.strip().str.lower()\n",
    "flights_test1['dest_city_name_only'] = flights_test1['dest_city_name_only'].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* make hour departure and arrival feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_test1['hour_departure'] = flights_test1['crs_dep_time'].apply(\n",
    "    lambda x: str(x)[:2] if len(str(x)) == 6 else (str(x)[:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_test1['hour_arrival'] = flights_test1['crs_arr_time'].apply(\n",
    "    lambda x: str(x)[:2] if len(str(x)) == 6 else (str(x)[:1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* categorize long, medium and short flights merge on flight mkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Short     424766\n",
       "Medium     63415\n",
       "Long        1840\n",
       "Name: flight_duration_type, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting to air_time\n",
    "def flight_duration(x):\n",
    "    if x <=180:\n",
    "        return 'Short'\n",
    "    elif x >180 and x<360:\n",
    "        return 'Medium'\n",
    "    elif x>=360:\n",
    "        return 'Long'\n",
    "\n",
    "flights['flight_duration_type']=flights['air_time'].apply(lambda x: flight_duration(x))\n",
    "flights['flight_duration_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping original air_time feature\n",
    "flights = flights.drop(['air_time', 'actual_elapsed_time'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* taxi-in categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "short_taxi_in     455478\n",
       "medium_taxi_in     34623\n",
       "long_taxi_in        9899\n",
       "Name: taxi_in_duration, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def taxi_in_duration(x):\n",
    "    if x <=15:\n",
    "        return 'short_taxi_in'\n",
    "    elif x > 15 and x<50:\n",
    "        return 'medium_taxi_in'\n",
    "    else:\n",
    "        return 'long_taxi_in'\n",
    "\n",
    "flights['taxi_in_duration']=flights['taxi_in'].apply(lambda x: taxi_in_duration(x))\n",
    "flights['taxi_in_duration'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* taxi-out categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "short_taxi_out     423700\n",
       "medium_taxi_out     65567\n",
       "long_taxi_out       10733\n",
       "Name: taxi_out_duration, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def taxi_out_duration(x):\n",
    "    if x <=25:\n",
    "        return 'short_taxi_out'\n",
    "    elif x > 25 and x<70:\n",
    "        return 'medium_taxi_out'\n",
    "    else:\n",
    "        return 'long_taxi_out'\n",
    "\n",
    "flights['taxi_out_duration']=flights['taxi_out'].apply(lambda x: taxi_out_duration(x))\n",
    "flights['taxi_out_duration'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* making df for taxis in and out and flight duration type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_time_df = flights[['mkt_carrier_fl_num', 'taxi_out_duration', 'taxi_in_duration', 'flight_duration_type']].drop_duplicates(subset = 'mkt_carrier_fl_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7010, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_time_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merging with test flights df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_test1 = pd.merge(taxi_time_df, flights_test1, on = 'mkt_carrier_fl_num', how = 'inner',validate = 'one_to_many') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_test1 = flights_test1.drop('mkt_carrier_fl_num', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* filling duration type nans with mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_duration_type = (flights_test1['flight_duration_type'].mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_test1['flight_duration_type'] = flights_test1['flight_duration_type'].fillna(str(mode_duration_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* arr_delay per unique_carrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_arrdelay_carrier = flights.groupby('mkt_unique_carrier')['arr_delay'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_arrdelay_carrier.name = 'mean_arrdelay_carrier'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_test1 = pd.merge(flights_test1, mean_arrdelay_carrier, how = 'left', on = ['mkt_unique_carrier'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* arrival delay per dest_airport id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_arrdelay_dest_air = flights.groupby('dest_airport_id')['arr_delay'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_arrdelay_dest_air.name = 'mean_arrdelay_dest_air'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_test1 = pd.merge(flights_test1, mean_arrdelay_dest_air, how = 'left', on = ['dest_airport_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* arrival delay per origin_airport id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_arrdelay_origin_air = flights.groupby('origin_airport_id')['arr_delay'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_arrdelay_origin_air.name = 'mean_arrdelay_origin_air'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_test1 = pd.merge(flights_test1, mean_arrdelay_origin_air, how = 'left', on = ['origin_airport_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* filling Nan with mean for airport delay means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_test1['mean_arrdelay_dest_air'] = flights_test1['mean_arrdelay_dest_air'].fillna(flights_test1['mean_arrdelay_dest_air'].mean())\n",
    "flights_test1['mean_arrdelay_origin_air'] = flights_test1['mean_arrdelay_origin_air'].fillna(flights_test1['mean_arrdelay_origin_air'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make the types categories from feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_test1[\"mkt_unique_carrier\"] = flights_test1[\"mkt_unique_carrier\"].astype(\"category\")\n",
    "flights_test1[\"origin_airport_id\"] = flights_test1[\"origin_airport_id\"].astype(\"category\")\n",
    "flights_test1[\"dest_airport_id\"] = flights_test1[\"dest_airport_id\"].astype(\"category\")\n",
    "flights_test1[\"flight_duration_type\"] = flights_test1[\"flight_duration_type\"].astype(\"category\")\n",
    "flights_test1[\"taxi_in_duration\"] = flights_test1[\"taxi_in_duration\"].astype(\"category\")\n",
    "flights_test1[\"taxi_out_duration\"] = flights_test1[\"taxi_out_duration\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* encoding categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODE AIRPORTS AND TAILNUM\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "flights_test1['mkt_unique_carrier'] = encoder.fit_transform(flights_test1[['mkt_unique_carrier']])\n",
    "flights_test1['origin_airport_id'] = encoder.fit_transform(flights_test1[['origin_airport_id']])\n",
    "flights_test1['dest_airport_id'] = encoder.fit_transform(flights_test1[['dest_airport_id']])\n",
    "flights_test1['taxi_in_duration'] = encoder.fit_transform(flights_test1[['taxi_in_duration']])\n",
    "flights_test1['taxi_out_duration'] = encoder.fit_transform(flights_test1[['taxi_out_duration']])\n",
    "flights_test1['flight_duration_type'] = encoder.fit_transform(flights_test1[['flight_duration_type']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* join on weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv('weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['City'] = weather['City'].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['date'] = pd.to_datetime(weather['StartTime(UTC)']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['EndTime(UTC)'] = pd.to_datetime(weather['EndTime(UTC)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = weather.groupby(['City', 'date']).max()['EndTime(UTC)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_merged = weather.merge(temp, on = ['City', 'date', 'EndTime(UTC)'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_merged = weather_merged.rename(columns = {'date': 'fl_date', 'City': 'origin_city_name_only'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_merged = weather_merged.drop(['StartTime(UTC)', 'EndTime(UTC)'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_merged['fl_date'] = pd.to_datetime(weather_merged['fl_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* finding weather between '2018-12-01 and 2019-01-30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_merged = weather_merged[(weather_merged['fl_date'] > '2018-12-01') & (weather_merged['fl_date'] < '2019-01-31')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#most common weather patterns per city during those times above\n",
    "weather_merged1 = weather_merged.groupby('origin_city_name_only').agg(lambda x:x.value_counts().index[0]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_merged1 = weather_merged1.drop('fl_date', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* merging weather with flights_test using origin city name as key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_test2 = pd.merge(flights_test1, weather_merged1, on = 'origin_city_name_only', how = 'left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping nulls\n",
    "flights_test2 = flights_test2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['taxi_out_duration', 'taxi_in_duration', 'flight_duration_type',\n",
       "       'fl_date', 'mkt_unique_carrier', 'origin_airport_id', 'dest_airport_id',\n",
       "       'crs_dep_time', 'crs_arr_time', 'dup', 'crs_elapsed_time', 'distance',\n",
       "       'month', 'day_of_week', 'day_of_month', 'year', 'origin_city_name_only',\n",
       "       'dest_city_name_only', 'hour_departure', 'hour_arrival',\n",
       "       'mean_arrdelay_carrier', 'mean_arrdelay_dest_air',\n",
       "       'mean_arrdelay_origin_air', 'Type', 'Severity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_test2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* dropping flights_weather row null values, origin_city_name_only, dest_city_name_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_test2 = flights_test2.drop(['origin_city_name_only', 'dest_city_name_only'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_test2 = flights_test2.drop(['fl_date'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Categorize and encode weather and severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_test2[\"Type\"] = flights_test2[\"Type\"].astype(\"category\")\n",
    "flights_test2[\"Severity\"] = flights_test2[\"Severity\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_test2['Type'] = encoder.fit_transform(flights_test2[['Type']])\n",
    "flights_test2['Severity'] = encoder.fit_transform(flights_test2[['Severity']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_test2 = flights_test2.drop('dup', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(561393, 21)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['taxi_out_duration', 'taxi_in_duration', 'flight_duration_type',\n",
       "       'mkt_unique_carrier', 'origin_airport_id', 'dest_airport_id',\n",
       "       'crs_dep_time', 'crs_arr_time', 'crs_elapsed_time', 'distance', 'month',\n",
       "       'day_of_week', 'day_of_month', 'year', 'hour_departure', 'hour_arrival',\n",
       "       'mean_arrdelay_carrier', 'mean_arrdelay_dest_air',\n",
       "       'mean_arrdelay_origin_air', 'Type', 'Severity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_test2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pickle module to save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predicting using test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* making the flights_test transformed into an array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(flights_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* pickle from linear elastic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_linear_Ela_pickle', 'rb') as linear_Elas_file:\n",
    "    model_elastic_linear = pickle.load(linear_Elas_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_linear_elastic =  model_elastic_linear.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = pd.DataFrame(y_predict_linear_elastic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict['y_predict'] = df_predict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = df_predict.drop(0, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([flights_test2, df_predict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taxi_out_duration</th>\n",
       "      <th>taxi_in_duration</th>\n",
       "      <th>flight_duration_type</th>\n",
       "      <th>mkt_unique_carrier</th>\n",
       "      <th>origin_airport_id</th>\n",
       "      <th>dest_airport_id</th>\n",
       "      <th>crs_dep_time</th>\n",
       "      <th>crs_arr_time</th>\n",
       "      <th>crs_elapsed_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>year</th>\n",
       "      <th>hour_departure</th>\n",
       "      <th>hour_arrival</th>\n",
       "      <th>mean_arrdelay_carrier</th>\n",
       "      <th>mean_arrdelay_dest_air</th>\n",
       "      <th>mean_arrdelay_origin_air</th>\n",
       "      <th>Type</th>\n",
       "      <th>Severity</th>\n",
       "      <th>y_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.423640</td>\n",
       "      <td>2.468765</td>\n",
       "      <td>2.099092</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>1153.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9.267684</td>\n",
       "      <td>6.672392</td>\n",
       "      <td>10.608652</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>1153.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9.267684</td>\n",
       "      <td>6.672392</td>\n",
       "      <td>10.608652</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>1153.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9.267684</td>\n",
       "      <td>6.672392</td>\n",
       "      <td>10.608652</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>1153.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9.267684</td>\n",
       "      <td>6.672392</td>\n",
       "      <td>10.608652</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561388</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.060969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561389</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.202651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561390</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.238038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561391</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.843979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561392</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.200579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1122786 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        taxi_out_duration  taxi_in_duration  flight_duration_type  \\\n",
       "0                     2.0               2.0                   3.0   \n",
       "1                     2.0               2.0                   3.0   \n",
       "2                     2.0               2.0                   3.0   \n",
       "5                     2.0               2.0                   3.0   \n",
       "7                     2.0               2.0                   3.0   \n",
       "...                   ...               ...                   ...   \n",
       "561388                NaN               NaN                   NaN   \n",
       "561389                NaN               NaN                   NaN   \n",
       "561390                NaN               NaN                   NaN   \n",
       "561391                NaN               NaN                   NaN   \n",
       "561392                NaN               NaN                   NaN   \n",
       "\n",
       "        mkt_unique_carrier  origin_airport_id  dest_airport_id  crs_dep_time  \\\n",
       "0                      9.0              349.0            301.0        1740.0   \n",
       "1                      8.0              248.0             83.0         925.0   \n",
       "2                      8.0              248.0             83.0         925.0   \n",
       "5                      8.0              248.0             83.0         925.0   \n",
       "7                      8.0              248.0             83.0         925.0   \n",
       "...                    ...                ...              ...           ...   \n",
       "561388                 NaN                NaN              NaN           NaN   \n",
       "561389                 NaN                NaN              NaN           NaN   \n",
       "561390                 NaN                NaN              NaN           NaN   \n",
       "561391                 NaN                NaN              NaN           NaN   \n",
       "561392                 NaN                NaN              NaN           NaN   \n",
       "\n",
       "        crs_arr_time  crs_elapsed_time  distance  ...  day_of_month    year  \\\n",
       "0             1800.0              80.0     368.0  ...           1.0  2020.0   \n",
       "1             1153.0              88.0     264.0  ...           1.0  2020.0   \n",
       "2             1153.0              88.0     264.0  ...           2.0  2020.0   \n",
       "5             1153.0              88.0     264.0  ...           3.0  2020.0   \n",
       "7             1153.0              88.0     264.0  ...           4.0  2020.0   \n",
       "...              ...               ...       ...  ...           ...     ...   \n",
       "561388           NaN               NaN       NaN  ...           NaN     NaN   \n",
       "561389           NaN               NaN       NaN  ...           NaN     NaN   \n",
       "561390           NaN               NaN       NaN  ...           NaN     NaN   \n",
       "561391           NaN               NaN       NaN  ...           NaN     NaN   \n",
       "561392           NaN               NaN       NaN  ...           NaN     NaN   \n",
       "\n",
       "        hour_departure  hour_arrival mean_arrdelay_carrier  \\\n",
       "0                    1             1              3.423640   \n",
       "1                    9             1              9.267684   \n",
       "2                    9             1              9.267684   \n",
       "5                    9             1              9.267684   \n",
       "7                    9             1              9.267684   \n",
       "...                ...           ...                   ...   \n",
       "561388             NaN           NaN                   NaN   \n",
       "561389             NaN           NaN                   NaN   \n",
       "561390             NaN           NaN                   NaN   \n",
       "561391             NaN           NaN                   NaN   \n",
       "561392             NaN           NaN                   NaN   \n",
       "\n",
       "       mean_arrdelay_dest_air  mean_arrdelay_origin_air  Type  Severity  \\\n",
       "0                    2.468765                  2.099092   2.0       0.0   \n",
       "1                    6.672392                 10.608652   3.0       0.0   \n",
       "2                    6.672392                 10.608652   3.0       0.0   \n",
       "5                    6.672392                 10.608652   3.0       0.0   \n",
       "7                    6.672392                 10.608652   3.0       0.0   \n",
       "...                       ...                       ...   ...       ...   \n",
       "561388                    NaN                       NaN   NaN       NaN   \n",
       "561389                    NaN                       NaN   NaN       NaN   \n",
       "561390                    NaN                       NaN   NaN       NaN   \n",
       "561391                    NaN                       NaN   NaN       NaN   \n",
       "561392                    NaN                       NaN   NaN       NaN   \n",
       "\n",
       "        y_predict  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "5             NaN  \n",
       "7             NaN  \n",
       "...           ...  \n",
       "561388  -5.060969  \n",
       "561389  -5.202651  \n",
       "561390  -5.238038  \n",
       "561391  -5.843979  \n",
       "561392  -5.200579  \n",
       "\n",
       "[1122786 rows x 22 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(r'C:\\Users\\kevin\\data_bootcamp\\w5\\d5\\mid-term-project-I-master/submission.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* pickle from linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "elasnet_model = ElasticNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_linear_pickle', 'rb') as linear_file:\n",
    "    model_linear = pickle.load(linear_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_linear = model_linear.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
